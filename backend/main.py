import os
import json
import re
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import google.genai as genai
from google.genai import types

# =========================
# Gemini API
# =========================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=GEMINI_API_KEY)

# =========================
# FastAPI
# =========================
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# Models
# =========================
class ChatResponse(BaseModel):
    reply: str

class Event(BaseModel):
    title: str
    date: str
    start_time: str
    end_time: str
    status: Optional[str] = ""
    location: Optional[str] = ""
    notes: Optional[str] = ""
    raw_text: Optional[str] = None
    source: Optional[str] = "image"

class ParseScheduleResponse(BaseModel):
    events: List[Event]

# =========================
# å¥åº·æª¢æŸ¥
# =========================
@app.get("/")
async def root():
    return {"status": "ok"}

# âœ…âœ…âœ… âœ…âœ…âœ… âœ…âœ…âœ…
# âœ…ã€1ã€‘åœ–ç‰‡ + æ–‡å­— åŒæ™‚é€çš„ API
# âœ…âœ…âœ… âœ…âœ…âœ… âœ…âœ…âœ…
@app.post("/chat-with-image", response_model=ChatResponse)
async def chat_with_image(
    message: str = Form(...),
    image: UploadFile = File(None)
):
    try:
        contents = []

        # âœ… æœ‰åœ–ç‰‡å°±ä¸€èµ·é€
        if image:
            img_bytes = await image.read()
            contents.append(
                types.Part.from_bytes(
                    data=img_bytes,
                    mime_type=image.content_type or "image/jpeg",
                )
            )

        # âœ… å¼·åˆ¶è¼¸å‡ºåªå›ç­”ä½¿ç”¨è€…å•é¡Œ
        prompt = f"""
ä½ æ˜¯ä¸€å€‹ã€Œè¡Œäº‹æ›† + ä¸€èˆ¬èŠå¤©ã€åŠ©ç†ã€‚

ã€åš´æ ¼è¦å‰‡ã€‘
1ï¸âƒ£ åªèƒ½å›ç­”ã€Œä½¿ç”¨è€…å•çš„é‚£ä¸€å¤©æˆ–é‚£ä¸€å€‹äº‹ä»¶ã€
2ï¸âƒ£ ç¦æ­¢åˆ—å‡ºæ•´å€‹æœˆ
3ï¸âƒ£ ç¦æ­¢è£œå……å…¶ä»–ç¯€æ—¥
4ï¸âƒ£ è‹¥åœ–ç‰‡ä¸­æ²’æœ‰è©²å•é¡Œçš„ç­”æ¡ˆï¼Œåªå›ï¼š
   ã€Œåœ–ç‰‡ä¸­æ²’æœ‰æ‰¾åˆ°è©²è³‡è¨Šã€

ã€è¼¸å‡ºæ ¼å¼ã€‘
ğŸ“… XX æ—¥è¡Œç¨‹ï¼š
â€¢ HH:MM ç‹€æ…‹
â€¢ HH:MM ç‹€æ…‹

ä½¿ç”¨è€…å•é¡Œï¼š
{message}
"""
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=contents + [prompt],
        )

        return ChatResponse(reply=response.text.strip())

    except Exception as e:
        return ChatResponse(reply=f"âŒ è§£æå¤±æ•—ï¼š{str(e)}")

# âœ…âœ…âœ… âœ…âœ…âœ… âœ…âœ…âœ…
# âœ…ã€2ã€‘ç´”èŠå¤©å®¤ï¼ˆæ²’æœ‰åœ–ç‰‡ï¼‰
# âœ…âœ…âœ… âœ…âœ…âœ… âœ…âœ…âœ…
@app.post("/chat", response_model=ChatResponse)
async def chat(message: str = Form(...)):
    try:
        prompt = f"""
ä½ æ˜¯ä¸€èˆ¬èŠå¤© AI åŠ©ç†ï¼Œè‹¥ä¸æ˜¯è¡Œäº‹æ›†å•é¡Œå°±æ­£å¸¸å°è©±ã€‚

ä½¿ç”¨è€…èªªï¼š
{message}
"""
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt]
        )
        return ChatResponse(reply=response.text.strip())

    except Exception as e:
        return ChatResponse(reply=f"âŒ éŒ¯èª¤ï¼š{str(e)}")
